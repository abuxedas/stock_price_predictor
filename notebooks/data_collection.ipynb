{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c255128a",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84f65652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8a42a2",
   "metadata": {},
   "source": [
    "# Get Data\n",
    "### We get the quarterly financial and stock price data from yahoo finance.\n",
    "### We will only keep the companies in the S&P500 with data since 2020-01-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756f0868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m3/_s6_yj8n00sdydg5rx4z5fjh0000gn/T/ipykernel_16458/2154613338.py:22: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(response.text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'AES', 'AFL', 'A']\n",
      "Number of Tickers: 503\n"
     ]
    }
   ],
   "source": [
    "# URL of the Wikipedia page containing the S&P 500 companies\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\";\n",
    "\n",
    "# Define HTTP headers to simulate a real browser\n",
    "# This helps avoid being blocked by the website (HTTP 403)\n",
    "headers = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/117.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Send an HTTP GET request with custom headers\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Raise an exception if the request failed (status code not 200)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Parse all HTML tables from the downloaded page\n",
    "# pandas.read_html can parse tables from a string of HTML\n",
    "tables = pd.read_html(response.text)\n",
    "\n",
    "# The first table on the page contains the S&P 500 companies\n",
    "sp500_table = tables[0]\n",
    "\n",
    "# Extract the 'Symbol' column to get the list of tickers\n",
    "tickers = sp500_table['Symbol'].tolist()\n",
    "\n",
    "# Print the first 10 tickers as a sanity check\n",
    "print(tickers[:10])\n",
    "print (f'Number of Tickers: {len(tickers)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc619931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m3/_s6_yj8n00sdydg5rx4z5fjh0000gn/T/ipykernel_16458/2502048630.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  prices = yf.download(tickers, start='2020-01-01')['Close']\n",
      "[*********************100%***********************]  503 of 503 completed\n",
      "\n",
      "3 Failed downloads:\n",
      "['BF.B']: YFPricesMissingError('possibly delisted; no price data found  (1d 2020-01-01 -> 2025-12-22)')\n",
      "['GM']: Timeout('Failed to perform, curl: (28) Connection timed out after 10001 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "['BRK.B']: YFTzMissingError('possibly delisted; no timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prices shape: (1502, 503)\n",
      "prices shape: (1502, 472)\n",
      "Number of tickers with closing price data since 2020-01-01 to current date: 472\n",
      "prices shape: (708944, 3)\n"
     ]
    }
   ],
   "source": [
    "#We download closing price of all tickers since 2020-01-01\n",
    "prices = yf.download(tickers, start='2020-01-01')['Close']\n",
    "\n",
    "print(f'prices shape: {prices.shape}')\n",
    "\n",
    "#We keep only tickers that have data since 2020-01-01\n",
    "prices = prices.dropna(axis=1)\n",
    "\n",
    "#We store the tickers in the DataFrame 'data'\n",
    "tickers = prices.columns.tolist()\n",
    "\n",
    "print(f'prices shape: {prices.shape}')\n",
    "\n",
    "print(f'Number of tickers with closing price data since 2020-01-01 to current date: {len(tickers)}')\n",
    "\n",
    "#We stack the values in 'data' to reorganize the DataFrame so we have columns 'Date', 'Ticker', 'close_stock_price'\n",
    "prices = pd.DataFrame(prices.stack()).reset_index().sort_values(['Ticker', 'Date'])\n",
    "prices.rename(columns={0: 'close_stock_price'}, inplace=True)\n",
    "\n",
    "print(f'prices shape: {prices.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb03aa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Success: 472 tickers\n",
      "✗ Failed: 0 tickers\n"
     ]
    }
   ],
   "source": [
    "# Create a financials dataframe with all quarterly financial statements of tickers with closing price data since 2020-01-01\n",
    "\n",
    "financials_list = []   # Create an empty list. Each element of the list will be a financials DF for each ticker\n",
    "failed_tickers = []    # Track errors\n",
    "\n",
    "for tkr in tickers:\n",
    "    try:\n",
    "        ticker = yf.Ticker(tkr)\n",
    "        income_q = ticker.quarterly_income_stmt         # Income statement, quarterly\n",
    "        balance_q = ticker.quarterly_balance_sheet      # Balance sheet, quarterly\n",
    "        cashflow_q = ticker.quarterly_cashflow          # Cash flow, quarterly\n",
    "        \n",
    "        # Validate that they are not empty \n",
    "        if income_q.empty or balance_q.empty or cashflow_q.empty:\n",
    "            print(f\"⚠️ {tkr}: Empty financial statements, skipping\")\n",
    "            failed_tickers.append(tkr)\n",
    "            continue\n",
    "        \n",
    "        # Combine all the financial data transposed (dates as row index and financials as columns)\n",
    "        financials_tkr = pd.concat([income_q.T, balance_q.T, cashflow_q.T], axis=1)\n",
    "\n",
    "\n",
    "        financials_tkr.reset_index(inplace=True)      # We reset the index\n",
    "        financials_tkr.columns.values[0] = 'Date'     # We rename the 1st column (old index) 'Date'\n",
    "        financials_tkr.insert(0, 'Ticker', tkr)       # Insert a column 'Ticker' at the beginning of the DataFrame to identify the company\n",
    "\n",
    "        # Add the financials DF to the list\n",
    "        financials_list.append(financials_tkr)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ {tkr}: Failed with error: {e}\")\n",
    "        failed_tickers.append(tkr)\n",
    "        continue  # Continue loop with next ticker\n",
    "\n",
    "financials = pd.concat(financials_list, axis=0, ignore_index=True)      # Concat the financials for all the tickers.\n",
    "\n",
    "# Final report\n",
    "print(f\"\\n✓ Success: {len(financials_list)} tickers\")\n",
    "print(f\"✗ Failed: {len(failed_tickers)} tickers\")\n",
    "if failed_tickers:\n",
    "    print(f\"Failed list: {failed_tickers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c018abc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m3/_s6_yj8n00sdydg5rx4z5fjh0000gn/T/ipykernel_16458/4269354273.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  financials['price_date'] = financials['Date'] + pd.Timedelta(days=5)\n"
     ]
    }
   ],
   "source": [
    "# Merge the DataFrames 'financials' and 'prices'\n",
    "\n",
    "# Get sure that Dates are in the correct format.\n",
    "financials['Date'] = pd.to_datetime(financials['Date'])\n",
    "prices['Date'] = pd.to_datetime(prices['Date'])\n",
    "\n",
    "# Create a new column price_date where we add 5 days to the column 'Date'\n",
    "# We do that in order to fix the look-ahead bias (stock prices react after some time of publishing financial results)\n",
    "financials['price_date'] = financials['Date'] + pd.Timedelta(days=5)\n",
    "\n",
    "# Merge using adjusted date. In case of not having a price for a date, we will use the next days price with a tolerance of 10 days.\n",
    "financials = pd.merge_asof(\n",
    "    financials.sort_values('price_date'),\n",
    "    prices.rename(columns={'Date': 'price_date'}).sort_values('price_date'),\n",
    "    on='price_date',\n",
    "    by='Ticker',\n",
    "    direction='forward',\n",
    "    tolerance=pd.Timedelta(days=10)\n",
    ")\n",
    "\n",
    "# We rename the index with ticker and date info so each observation is easier to track in the future\n",
    "financials = financials.set_index(\n",
    "    financials['Ticker'] + \"_\" + financials['Date'].dt.strftime('%Y-%m-%d')\n",
    ")\n",
    "\n",
    "financials.sort_values(['Ticker', 'Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a907ef6",
   "metadata": {},
   "source": [
    "# We save the data as a pickle in the folder 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1035974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved successfully in ../data/raw_financials.pkl\n"
     ]
    }
   ],
   "source": [
    "#We save the 'financials' DataFrame as a pickle with the name raw_financials.pkl in the 'data' folder\n",
    "#We save the data folder path or create it if it doesn't exist\n",
    "project_path = Path('..')          \n",
    "data_folder = project_path / 'data' \n",
    "data_folder.mkdir(exist_ok=True) \n",
    "\n",
    "#We save the DataFrame in pikle format\n",
    "file_path = data_folder / 'raw_financials.pkl'\n",
    "financials.to_pickle(file_path)\n",
    "\n",
    "print(f\"DataFrame saved successfully in {file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
